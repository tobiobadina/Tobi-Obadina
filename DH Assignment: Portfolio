```html
<!DOCTYPE html>
<html>
<head>
<title>Page Title</title>
</head>
<body>
<h1>Digital Artefact Creation</h1>
</body>
</html>
```

<h1> Final Assignment: Portfolio Reflection 

Over the past couple of weeks, this course has explored the transformative role of digital technologies in society, drastically impacting themes of communication, knowledge, and historical documentation. Through reading articles, watching videos, and discussions, I have developed a deeper understanding of how digital tools such as VR, AR, XR, AI systems and online platforms influence the way we access, interact and share information. This portfolio reflects on these certain topics, combining research and engagement with personal insights and practical reflection of their significance. 

1. The Internet’s Own Boy 
Watching The Internet’s own boy highlighted the tension between openness and control in the digital world. The film illustrates how access to academic knowledge is often restricted by paywalls and privately owned publishing organisations, drastically limiting public access. Before watching the documentary, I had not fully understood the financial and political barriers that prevent people from accessing publicly funded research. It made me realise how easy it is to take information for granted when the majority of knowledge online is only available to those who can afford it. This pushed me to reflect on the ethical implications of digital knowledge: if information is produced with public resources, should it be freely available? 

The documentary also made me think about who benefits from restricted access. Large publishing companies profit from knowledge that academics and institutions have created, while students, researchers, and the public are left behind. Digital tools have the power to make knowledge available to everyone, but they can only do so if systems support openness. This highlighted the importance of advocating for open access policies in universities, libraries, and governments to ensure that learning is fair for all. The film made me appreciate the importance of transparency, digital rights, and the people who fight for information equality. 

2. Social Media & the Web 
Eli Pariser’s TED talk on filter bubbles, alongside the principles in A Contract for the Web, highlighted how algorithms shape not only our online experiences but also our beliefs, behaviours, and social interactions. Principle 5 emphasises protecting personal data, while Principle 8 focuses on building respectful online communities. Together, these principles show that the health of the internet depends on both privacy and kindness. 

Protecting privacy helps build trust, which in turn supports more meaningful and civil interactions online. However, Pariser explains that algorithm-driven content can trap people in narrow ideological spaces. When we only see information that matches our preferences, we lose exposure to different viewpoints. Over time, this can create misunderstanding, polarisation, and an inability to think critically. Reflecting on this made me more aware of my own online habits and how often I accept online content without questioning why it appears. It reminded me that algorithms do not show us the full picture, there are always multiple sides to every story. 

This reflection has encouraged me to seek more diverse sources, question digital platforms, and avoid relying too heavily on tailored content. It also showed me why digital skills and critical thinking are essential in a world shaped by invisible algorithms. 

3.Should All Archives Be Open Access?
The readings on archives, especially Istvan Rev’s work, showed that archives are no longer just places to store documents, they now play an active role in helping society understand history. People increasingly expect political, cultural, and historical records to be available online, and digital conversion has made this possible. 

However, making archives accessible also comes with important responsibilities. Information must be shared with proper context to avoid misunderstandings, and sensitive records must be handled carefully to protect privacy. Examples such as the rehabilitation of World War I soldiers or Rwandan genocide survivors show how archival records can deeply affect people’s lives. These cases demonstrate that archives hold power, they can restore dignity, reveal injustice, or reopen painful histories. 

Reflecting on this made me see archives as careful caretakers of information, where access and responsibility must go hand in hand. It reminded me that openness is valuable, but it must never override the safety or integrity of the people involved. 

4.What Potential Applications for VR, AR, and XR Do You Envisage? 
Exploring VR, AR, and XR broadened my understanding of how immersive technologies can support learning, healthcare, and professional collaboration. VR provides fully immersive simulations for safe training, such as medical practice or emergency response. AR overlays helpful information onto the real world, improving tasks like navigation or equipment repair. XR blends both worlds for shared digital and physical experiences, such as remote teamwork or virtual classrooms. 

These tools are more than entertainment, they can change how we approach education, therapy, architecture, and workplace productivity. For example, VR can help students visualise complex concepts, while AR can assist surgeons during operations. Reflecting on these technologies made me realise that innovation must be paired with ethical design. Accessibility, usability, and responsible implementation are essential to ensure everyone benefits, not just those with access to expensive equipment. 

5.Responses to Anatomy of an AI System 
Discussions about AI made me think carefully about what it can do and how it affects society. AI influences the content we see, the decisions we make, and even how history is presented online. While AI can make tasks faster and smoother, it can also cause serious problems like bias, lack of transparency, and unfair outcomes. 

Reflecting on AI showed me that we need ethical rules, regulations, and oversight to make sure it helps people without widening inequalities or spreading misleading information. Understanding how AI systems are built, who trains them, what data they use, and whose voices are included, helped me see why digital fairness matters. AI is powerful, but it must be guided responsibly. 

6.Where Might the Internet of Sounds Go from Here? 
Projects like the Internet of Sounds showed how digital media is transforming cultural creation and access. Audio, like text or video, can now be archived, shared, and experienced globally. This makes culture and memory more accessible and allows more people to create and enjoy media. 

However, these technologies also raise issues such as the risk of getting hacked, loosing files, ownership rights, and the responsibility to respect cultural meaning. Not everything should be shared without permission, and not every recording fits easily into digital spaces. Reflecting on this showed me that enthusiasm for new technology must be balanced with critical thinking and ethical consideration. 

7.AI Bias and Ethical Coding 
I found Joy Buolamwini’s TED talk on bias in algorithms particularly eye-opening. Despite major advances in AI, these systems are far from perfect. When Buolamwini tested facial recognition software, it failed to recognise her because it was designed mainly for lighter skin tones. This showed that AI systems often reflect the biases of their creators, which can lead to harmful outcomes. If flawed facial recognition is used in policing or legal contexts, someone could be wrongly accused or even imprisoned. This made me realise that coding and programming are not just technical tasks, they come with serious ethical responsibility. To create fair and safe AI systems, developers must think about who is coding, how they are coding, and why they are coding. Applying these principles can lead to more accurate, equal, and socially responsible technology that avoids causing harm. 


Reflecting on this course has helped me understand that digital technologies are not automatically positive or negative, their effects depend on how we design them, how we use them, and the rules we put in place to guide them. Tools like open access platforms, VR and AR, AI systems, and online communities can greatly improve how we learn, create, and connect with others. They can make information easier to share and give more people a chance to participate in digital life. 

At the same time, these technologies also bring challenges. They raise important questions about privacy, fairness, accuracy, ownership, and the potential misuse of data. They can help society move forward, but if they are not managed carefully, they can also create inequalities or cause harm. 

Working on this portfolio has shown me that being able to understand digital tools, and think critically about their impact, is more important than ever. Digital skills, ethical awareness, and responsible decision-making are essential skills if we want to use technology in ways that benefit everyone. As the digital world continues to grow and shape our daily lives, it is our responsibility to engage with it thoughtfully and help create a fairer and more beneficial future for everyone. 
</h1>
